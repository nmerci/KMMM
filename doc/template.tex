
\documentclass{tbimc}
%%
% Place your definitions here
\usepackage{bbm}
 \usepackage{relsize}
\newtheorem{thm}{Теорема}[section]
\newtheorem{lem}{Лема}[section]
\newtheorem{nas}{Наслідок}[section]
\theoremstyle{remark}
\newtheorem{zau}{Зауваження}[section]
\theoremstyle{definition}
\newtheorem{ozn}{Означення}[section]

\DeclareMathOperator{\bcdot}{\boldsymbol\cdot}
\DeclareMathOperator{\pr}{\mathsf P}
\DeclareMathOperator{\M}{\mathsf E}
\DeclareMathOperator{\D}{Var}
\newcommand{\bydef}{\stackrel{\text{\rm def}}{=}}
%\DeclareMathOperator*{\pint}{\mathlarger{\mathlarger{\mathlarger{\mathlarger{\mathlarger{\boldsymbol{\pi}}}}}}}
\DeclareMathOperator*{\pint}{\mathlarger{\mathlarger{\mathlarger{\mathlarger{\mathlarger{\pi}}}}}}
%%
\newcommand{\R}{\mathbb R}

\begin{document}

%\selectlanguage{english}

\title[Оцінка Каплана-Мейєра для моделі сумішей]
    {Модифікація оцінки Каплана-Мейєра для моделі сумішей зі змінними концентраціями}

%    Information for first author
\author{Р. Є. Майборода}
\address{Кафедра теорії ймовірностей, математичної статистики і актуарної математики
    механіко-математичний факультет,
    Національний університет ім.~Тараса Шевченка,
    проспект Глушкова, 6,
    Київ 03127,
    Україна}
\email{mre@univ.kiev.ua}

%    Information for second author
\author{В. Г. Хізанов}
\address{Кафедра теорії ймовірностей, математичної статистики і актуарної математики
    механіко-математичний факультет,
    Національний університет ім.~Тараса Шевченка,
    проспект Глушкова, 6,
    Київ 03127,
    Україна}
\email{vl.khizanov@gmail.com}

%    General info
\subjclass[2000]{62N05 ; 62G05}
%\date{29/09/2003}
\keywords{Оцінка Каплана-Мейєра, моделі сумішей зі змінними
концентраціями, консистентність, цензурування
\\
Kaplan-Meier estimator, mixtures with varying concentrations.
consistency, censoring}

\begin{abstract}
Запропонована модифікація оцінки Каплана-Мейера для оцінювання
розподілу компонентів суміші зі змінними концентраціями за
цензурованими даними. Доведена консистентність цих оцінок у
 рівномірній нормі та
отримана верхня межа для швидкості їх збіжності.

 A modification of Kaplan-Meier estimator is proposed for mixture
 components CDFs estimation by censored data in the case when
 mixing probabilities vary from observation to observation.
 Consistency of the estimators in the sup-norm is demonstrated and
 an upper bound for the convergence rate is derived.
\end{abstract}

\maketitle

\section{Вступ}

Задача оцінювання розподілу тривалості життя за спостереженнями,
випадково цензурованими зправа, природно виникає у актуарній та
медічній статистиці, а також при аналізі надійності приладів
\cite{Korosteleva,HLMN}. У випадку, коли цензуровані спостереження
є незалежними та однаково розподіленими, найбільш поширеною
оцінкою для функції розподілу є оцінка Каплана-Мейєра \cite{Shao}.
У даній роботі ми розглядаємо модифікацію цієї оцінки для випадку,
коли спостережувані об'єкти вибирають з суміші, причому концентрації компонентів у цій суміші змінюються від спостереження до спостереження.
Схожа задача розглядалась у роботі А. Рижова \cite{Ryzhov}.
Але запропоновану у \cite{Ryzhov} техніку оцінювання можна використовувати лише у випадку,
коли концентрації компонентів у суміші приймають значення з деякого скінченного
набору чисел. У даній роботі пропонується оцінка, яку можна використовувати
для довільних концентрацій. При побудові цієї оцінки використані результати
роботи Р. Д. Гілла та С. Йохансена \cite{GJ}, де оцінка Каплана-Мейєра
трактується як продакт-інтеграл від оцінки інтегральної функції ризику.
Крім того, ми використовуємо для оцінювання навантажені емпіричні розподіли,
застосування яких для сумішей зі змінними концентраціями розглядалось у роботах Р. Майбороди
та О. Сугакової \cite{MS, MSua}. Про задачі, що приводять до
моделі суміші зі змінними концентраціями див. також
\cite{Sherbina2011,AutinPouet}.



Далі у п. \ref{sec:postanovka} формально описана ймовірнісна
модель даних, та запропонована модифікація оцінки Каплана-Мейєра
для них. Тут також сформульована теорема про умови рівномірної
консистентності цієї оцінки та швидкість її збіжності. У п.
\ref{sec:dopvidomosti} містяться допоміжні відомості про
продакт-інтеграли. П. \ref{sec:dovedennia} присвячено доведенню
теореми про консистентність. У п. \ref{sec:modeluvannia} описано
результати дослідження поведінки оцінок на модельованих вибірках.

\section{Постановка задачі}
\label{sec:postanovka} Розглянемо вибірку з $n$ об'єктів $O_1,
\ldots ,O_n$ з суміші зі змінними концентраціями, тобто будемо
вважати, що кожен $O_j$ належить одній з $M$ популяцій
(компонентів суміші). Позначимо $\mathrm{ind}(O_j)$ --- номер
популяції, якій належить $O_j$. Вважаємо, що значення
$\mathrm{ind}(O_j)$ невідомі, але відомі концентрації компонентів
у суміші при відборі $O_j$, тобто $w_j^m = \mathbb P
(\mathrm{ind}(O_j)=m), m=1,\ldots ,M$. Для кожного $O_j$ існує
невід'ємна характеристика $\xi _j = \xi (O_j)$, яку будемо
називати тривалістю життя $O_j$. Розподіл $\xi (O)$ залежить від
того, якому компоненту належить $O$:
\begin{equation*}
F_m(A) = \pr (\xi (O) \in A \mid \mathrm{ind}(O) = m)
\end{equation*}

Ми вважаємо, що при спостереженні $O_j$ відбувається випадкове
цензурування зправа, тобто спостерігається пара $\xi ^*_j = \min (\xi _j, c_j)$
 та $\delta _j = \mathbbm 1\{\xi ^*_j \leq c_j\}$, де $c_j$
 --- невід'ємна випадкова величина, що зветься цензором.
  При цьому розподіл $c_j$ також може бути різним для різних компонентів:
\begin{equation*}
G_m (A) = \pr (c_j \in A \mid \mathrm{ind}(O_j) = m)
\end{equation*}
Задача полягає в тому, щоб оцінити функцію розподілу $\xi (O)$ для
$m$-ого компонента, тобто $F_m(x) = F_m((-\infty ,x])$, за
спостереженнями $(\xi ^* _j , \delta _j )_{j=1}^n$. При цьому
випадкові вектори $(\xi _j, c_j)$ вважаються незалежними при
різних $j$, $\xi _j$ та $c_j$ незалежні при фіксованому
$\mathrm{ind}(O_j)$. Концентрації $w_j^m$ $j=1,\dots,n$,
$m=1,\dots,M$ вважаються відомими, розподіли $F_m$ та $G_m$ ---
невідомими.

 Ми будемо досліджувати асимптотичну поведінку оцінок при зростанні обсягу
 вибірки: $n\to\infty$. При цьому спостережувані об'єкти $O_j$ та
 відповідні концентрації $w_j^k$ при різних $n$ ніяк між собою не
 пов'язані, тобто $\xi_j=\xi_{j;n}$, $w_j^m=w_{j;n}^m$. Для
 спрощення позначень індекс $n$ надалі писати не будемо.

Надалі функцію розподілу будемо позначати тією ж літерою, що і
відповідний розподіл. Наприклад, $G_m(t) = G_m((-\infty ,t])$,
$G_m (t-)=\lim _{s\uparrow t} G_m (s) = G_m((-\infty ,t))$ ---
неперервна зліва версія функції розподілу. Відповідна функція
виживання позначається рискою вгорі: $\overline{G}_m(t) = 1 -
G_m(t), \overline{F}_m(t) = 1 - F_m(t)$.

Позначимо також
\begin{equation*}
N_m(t) = \pr (\xi ^* _j \leq t , \delta _j = 1 \mid
\mathrm{ind}(O_j) = m) = \int _{(0, t]}\overline{G}_m(s-)F_m(ds)
\end{equation*}
\begin{equation*}
Y_m(t) = \pr (\xi ^* \geq t \mid \mathrm{ind}(O_j) = m ) =
\overline{G}_m (t- ) \overline{F}_m(t-)
\end{equation*}
Тоді
\begin{equation}
\label{eq:KM_ord} \overline{F}_k(t) = \pint\limits_{(0, t]}\left(1
- \frac {N_k(ds)}{Y_k(s)}\right),
\end{equation}
де $\pint (1 + d\alpha)$ позначає продакт-інтеграл за
диференціалом адитивної функції $\alpha$ (докладніше див. у п.
\ref{sec:dopvidomosti}).

 Зафіксуємо $k$ --- номер компонента, для якого проводиться
 оцінювання.
Для того, щоб оцінити $\overline{F}_k(t)$ (і, відповідно, $F_k(t) = 1 - \overline{F}_k(t)$) ми оцінимо $N_k$ та $Y_k$
і підставимо відповідні оцінки у (\ref{eq:KM_ord})
замість справжніх значень. Як показано у \cite{MS}, на роль оцінок
$N_k$ та $Y_k$ можна використовувати відповідні навантажені емпіричні функції розподілу:
\begin{equation}
\label{eq:est_Nk}
\hat N_{k, n}(t) = \frac 1n \sum _{j=1}^n a_j^k \mathbbm 1\{\xi ^*_j \leq t , \delta _j = 1 \},
\end{equation}
\begin{equation}
\label{eq:est_Yk} \hat Y_{k, n}(t) = \frac 1n \sum _{j=1}^n
a_j^k\mathbbm 1 \{\xi _j^* \geq t\}
\end{equation}
Тут $\mathbf a^k = (a^k_1, \ldots ,a^k_n)$ --- невипадкові вагові
коефіцієнти, що не залежать від спостережень, але залежать від
концентрацій $w_j^m$. Для того, щоб оцінки (\ref{eq:est_Nk}) та
(\ref{eq:est_Yk}) були незміщеними, досить, щоб
\begin{equation}
\label{eq:unbiasedness} \frac 1n \sum _{j = 1}^n w_j^m a_j^k =
\mathbbm 1\{k=m\},\quad m =1,\ldots ,M
\end{equation}
Як показано у \cite{MS}, у класі всіх незміщених оцінок мінімаксними є оцінки з ваговими коефіцієнтами
\begin{equation}
\label{eq:est_Ak}
\mathbf a^k = \mathbf e^k \mathbf{\Gamma }_n^{-1} \mathbf W_n^\top,
\end{equation}
де $\mathbf e^k  = (\mathbbm 1\{k = \ell\})_{\ell =1}^M$ ---
вектор-рядок, $\mathbf W_n=(w_j^m)_{j=1\dots,n; m=1\dots,M}$ ---
$n\times M$ матриця концентрацій, $\mathbf \Gamma _n = (\frac 1n
\sum _{j=1}^n w^m_j w^l_j)_{m, l = 1}^M$ (за умови, що $\det
\mathbf \Gamma _n \neq 0$).

Надалі ми будемо розглядати переважно оцінки (\ref{eq:est_Nk}), (\ref{eq:est_Yk}) з ваговими коефіцієнтами вигляду
 (\ref{eq:est_Ak}), але теорема \ref{thm:1} є вірною для будь-яких
 вагових коефіцієнтів, що задовольняють її умови.

Таким чином, оцінка для $F_k(t)$ набуває вигляду:
\begin{equation}
\label{eq:KMM} \hat F_{k,n}(t) = 1 - \pint\limits_{(0, t]}\left(1
- \frac {d\hat N_{k, n}(s)}{\hat Y_{k, n}(s)}\right) = 1 - \prod
_{j:\xi ^*_j \leq t}\left(1 - \frac {a^k_j \delta _j}{n -
\sum\limits_{i:\xi ^* _i < t} a_i^k} \right)
\end{equation}

Зауважимо, що у випадку, коли всі $\xi ^*_j$ однаково розподілені, а $a_j^k = 1$, оцінка (\ref{eq:KMM}) перетворюється на звичайну оцінку Каплана-Мейєра для функції розподілу за однорідними цензурованими спостереженнями.

Позначимо $\ell _n = \sqrt{\frac {\ln n}{n}}$, $\overline{ a}_n^k
= \sup _{j=1,\ldots ,n}|a_j^k|$, $\tau _k = \sup \{t :
\overline{F}_k(t) \overline{G}_k(t) > 0\}, k=1,\ldots ,M$.

\begin{thm}
\label{thm:1} Нехай $T_k\in \mathbb R: 0<T_k < \tau _k$ і для
$a_j^k$ виконуються умови (\ref{eq:unbiasedness}) та $\ell _n
(\overline{a}_n^k)^2\to 0$ при $n\to \infty$. Тоді існує така
випадкова величина $0 < \eta < \infty $ м. н., що
\begin{equation*}
\sup _{t\in [0, T_k]}|\hat F_{k,n}(t) - F_k(t)| \leq \eta\ell _n
(\overline{a}^k_n)^3
\end{equation*}
\end{thm}

\begin{nas}
Якщо вагові коефіцієнти $a_j^k$ визначаються (\ref{eq:est_Ak}) і
$\ell _n(\det \mathbf \Gamma _n)^{-3}\to0$, то $\hat F_{k,n}(t)$ є
рівномірно сильно консистентною оцінкою для $F_k(t)$ на відрізку
$[0, T_k]$.
\end{nas}
Дійсно, оскільки ймовірності $0\le w_j^m\le 1$, то для $a_j^k$
заданих (\ref{eq:est_Ak}), $\overline{a}_n^k\le C\det\Gamma_n$.

Відмітимо, що при $\det \mathbf \Gamma_n=0$ вектори  концентрацій
компонентів $\mathbf w^m=(w_1^m,\dots,w_n^m)$, $m=1,\dots, M$ є
лінійно залежними.
 У цьому (виродженому) випадку задача оцінювання функцій розподілу
 компонентів стає неідентифіковною навіть при відсутності
 цензурування \cite{MS} і, отже, консистентне оцінювання
 неможливе. Тим не менше, наслідок показує, що оцінки
 $\hat F_{k,n}$ будуть консистентними, якщо
 $\det \mathbf \Gamma_n\to 0$ але не занадто швидко.


\section{Допоміжні відомості}
\label{sec:dopvidomosti} Слідуючи \cite{GJ}, нагадаємо поняття
мультиплікативного інтегралу, яке буде використовуватися у
доведенні теореми про сильну консистентність модифікованої оцінки
Каплана-Мейєра. Розглянемо розбиття інтервалу $(0, t]$ та
позначимо його через
\begin{equation}
    P = \{0 = t_0 < t_1 < \ldots <t_{|P|}=t\}
\end{equation}
Через $\mathcal{P}$ будемо позначати клас усіх розбиттів таких, що
\begin{equation}
    \max _{t_i \in P}|t_{i+1}-t_i|\to 0, |P|\to \infty
\end{equation}
\begin{ozn}
Функція $\alpha(u,v)$, визначена для $0\le u<v\le t$, називається
адитивною функцією, якщо для всіх $0\le u<v<s < \infty$
$$
\alpha(u,s)=\alpha(u,v)+\alpha(v,s).
$$
\end{ozn}
\begin{ozn}
Нехай $\alpha$ --- адитивна неперервна справа функція. Тоді мультиплікативним інтегралом називається границя:
\begin{equation}
\pint\limits_{(0, t]}(1 + \alpha (ds)) = \lim _{\substack{P\in
\mathcal P:\\|P|\to \infty}}\prod _{i=1}^{|P|}\left(1 + \alpha
(t_{i-1}, t_{i})\right)
\end{equation}
\end{ozn}
Для довільних функцій $f,g:[0,t]\to\R$ позначимо
$$
\pint\limits_{(0,t]}\left(1+f(s)dg(s)\right)
 =\pint\limits_{(0,t]}\left(1+d\alpha\right),
$$
 де
 $\alpha(u,v)=\int_u^v f(s)dg(s)$.

Надалі фіксуємо $T_k$, що відповідає умові теореми \ref{thm:1} і будемо позначати $\|x\|_\infty = \sup _{t\in [0, T_k]}|x(t)|$, $\|x\|_v$ --- повна варіація $x(t)$ на інтервалі $[0, T_k]$.
\begin{lem}
\label{lem:1} Нехай $\alpha ,\alpha _n$ ---  адитивні функції.
Покладемо $\mu _n (t) =\pint\limits _{(0, t]} (1 + d\alpha _n )$,
$\mu (t) = \pint\limits _{(0, t]} (1 + d\alpha  )$. Тоді
\begin{equation*}
\|\mu _n - \mu\|_\infty \leq 4\|\mu \|_v\exp (\|\alpha _n\|_\infty)\|\alpha _n\|_v \|\alpha _n - \alpha \|_\infty
\end{equation*}
\end{lem}
\emph{Доведення} випливає з наступних нерівностей, отриманих у
\cite{GJ} при доведенні теореми 7:
\begin{equation*}
\|\mu _n - \mu\|_\infty \leq 4\|\mu _n \|_v\|\mu \|_v \|\alpha _n - \alpha \|_\infty
\end{equation*}
та
\begin{equation*}
\|\mu _n \|_v \leq \exp (\|\alpha _n\|_\infty) \|\alpha _n\|_v
\end{equation*}
\qed


\section{Доведення теореми}
\label{sec:dovedennia} Позначимо $\Lambda _k (s,t ) = \int _{(s,
t]}\frac {d N_{k}(u)}{Y_{k}(u)}$, $\Lambda _k(t) = \Lambda _k(0,
t)$ і $\hat \Lambda _{k, n}(s,t ) = \int _{(s, t]}\frac {d \hat
N_{k,n}(u)}{\hat Y_{k,n}(u)}$, $\hat \Lambda _{k, n}(t) = \hat
\Lambda _{k, n}(0, t)$. Функцію $\Lambda _k(t)$ називають
(інтегральною або кумулятивною) функцією ризику для тривалості
життя з розподілом $F_k$.
\begin{lem}
\label{lem:2}
Нехай для $a_j^k$ виконуються умови незміщеності (\ref{eq:unbiasedness}).
 Тоді існує така випадкова величина $\eta _0: 0 < \eta _0 < \infty$ м. н., що
\begin{equation*}
\|\hat N_{k, n} - N\|_\infty \leq \eta _0 \ell _n \overline{a}^k_n
\end{equation*}
\begin{equation*}
\|\hat Y_{k,n} - Y\|_\infty \leq \eta _0 \ell _n\overline{ a}^k_n
\end{equation*}
\end{lem}
\emph{Доведення}. розглянемо випадкові вектори $\zeta _j = (\xi ^*_j, \delta _j)$.
 Легко бачити, що набір $(\zeta _1, \ldots , \zeta _n)$ являє собою вибірку з суміші зі змінними концентраціями:
\begin{equation*}
\mathbb P(\zeta _j \leq \mathbf z) = \sum _{k=1}^m w_j^kH_k(\mathbf z),
\end{equation*}
де
 $\mathbf z=(z_1,z_2)\in\R^2$,
$$H_k(\mathbf z) = \mathbb P(\min (\xi (O_j), c_j) \leq z_1,
\mathbbm 1\{\xi (O_j) \leq c_j\} \leq z_2 \mid \mathrm{ind}(O_j) =
k)$$
 --- функція розподілу $\zeta _j$ за умови, що $O_j$ належить
$k$-ому компоненту суміші. Застосувавши до $\zeta _j$ наслідок
2.2.4 з \cite{MSua}, отримуємо, що існує така випадкова величина
$\eta _1 < \infty$ м. н., для якої
\begin{equation}
\label{eq:convspeed}
\sup _{\mathbf z\in \mathbb R^2}|\hat H_{k, n}(\mathbf z) - H_k(\mathbf z)|
 \leq \eta _1\ell _n\overline{a}^k_n,
\end{equation}
де $\hat H_{k,n}(\mathbf z) = \frac 1n \sum _{j=1}^n a_j^k\mathbbm 1\{\zeta _j \leq \mathbf z \}$. Оскільки $\hat Y_{k, n}(t) = 1 - \hat H_{k, n}(t, 1)$, $Y(t) = 1 - H_k (t, 1)$, $\hat N_{k, n}(t) = \hat H_{k, n}(t, 1) - \hat H_{k, n}(t, 0)$, $N_k(t) = H_k(t,1) - H_k(t,0)$, з (\ref{eq:convspeed}) отримуємо твердження леми.\qed

\begin{lem}
\label{lem:3} В умовах теореми \ref{thm:1} існують такі випадкові
величини $\eta _2:\eta _2<\infty $ м. н. і $n_0<\infty$ м.н., що
для всіх $n>n_0$
\begin{equation*}
\|\hat\Lambda _{k, n} - \Lambda _k\|_\infty \leq \eta _2\ell _n
\overline{ a}^k_n
\end{equation*}
\end{lem}
\emph{Доведення}. За означенням $\Lambda$ і $\hat \Lambda$ отримуємо
\begin{equation}
\label{eq:lemproof1}
\|\hat\Lambda _{k, n} - \Lambda _k\|_\infty = \sup _{t\in [0, T]}
 \left|\int _{(0, t]} \frac {d\hat N_{k, n}(s)}{\hat Y_{k,n}(s)}
 - \int _{(0, t]} \frac {d N_{k}(s)}{ Y_{k}(s)} \right| \leq I_1 + I_2,
\end{equation}
де
\begin{equation*}
I_1 = \sup _{t\in [0, T]} \left|\int _{(0, t]}
 \left(\frac
{1}{\hat Y_{k,n}(s)} - \frac {1}{Y_k(s)}
 \right)d\hat N_{k,n}(s)\right|,
\end{equation*}
\begin{equation*}
I_2 = \sup _{t\in [0, T]} \left|\int _{(0, t]} \frac {d(\hat
N_{k,n}(s) - N_k(s))}{Y_k(s)}\right|
\end{equation*}
Оцінимо $I_1 \leq \| \frac {\hat Y_{k, n} - Y_k}{\hat Y_{k, n} Y_k} \|_\infty \|\hat N_{k,n}\|_v$.
Оскільки $T_k < \tau _k $, $\sigma _k = \inf \{t \in [0, T_k] \mid Y_k > 0\}$
 і за лемою \ref{lem:2} отримуємо, що $\inf _{t\in [0, T]} |\hat Y_{k, n}(t)| >
 \sigma _k+ \eta _0\ell _n\overline{a}^k_n$. Отже, при достатньо  великих $n$,
\begin{equation*}
\| \frac {\hat Y_{k, n} - Y_k}{\hat Y_{k, n} Y_k} \|_\infty \leq
\frac {\|\hat Y_{k, n} - Y_k\|_\infty } {\sigma _k(\sigma _k- \eta _0\ell
_n \overline{a}^k_n)} \leq \frac {\eta _0\ell _n \overline{
a}^k_n }{\sigma _k(\sigma _k - \eta _0\ell _n \overline{a}^k_n)}
\end{equation*}
Функція $\hat N_{k,n}$ є сталою на інтервалах між стрибками зі
стрибками висоти $\frac 1n a_j^k$. Тому
\begin{equation*}
\|\hat N_{k, n}\|_v \leq \frac 1n \sum _{j=1}^n |a_j^k|\leq
\overline{ a}^k_n
\end{equation*}
Таким чином,
\begin{equation}
\label{eq:lemproof2} I_1 \leq \frac {\eta _0\ell _n (\overline{
a}^k)^2_n}{\sigma _k(\sigma _k - \eta _0\ell _n \overline{ a}^k_n)}
\end{equation}

Оцінимо $I_2$ інтегруванням частинами:

\begin{align*}
I_2 =& \sup _{t\in [0, T_k]}\left|\frac {\hat N_{k, n}(s) -
N_k(s)}{Y_k(s)}\biggr\rvert _{s=0+}^t - \int _{(0, t]} (\hat N_{k,
n}(s) - N_k(s))d\frac {1}{Y_k(s)}\right |  \\ & \leq 2\frac
{\|\hat N_{k, n} - N_k\|_\infty }{\sigma _k} + \|\hat N_{k, n} -
N_k\|_\infty \|\frac {1}{Y_k}\|_v
\end{align*}
Оскільки $Y_k$ є монотонно неспадною функцією і $Y_k > \sigma _k $
при $t\in [0, T_k]$, то $\|\frac {1}{Y_k}\|_v < \infty$.

Отже, за лемою \ref{lem:2}
\begin{equation}
\label{eq:lemproof3} I_2 \leq \frac {2}{\sigma _k} \eta _0 \ell _n
\overline{ a}^k_n + \eta _0 \ell _n \overline{ a}^k_n \|\frac
{1}{Y_k}\|_v
\end{equation}

З умови (\ref{eq:unbiasedness}) випливає, що $\overline{ a}^k_n
\geq 1$. Тому, об'єднуючи (\ref{eq:lemproof1}),
(\ref{eq:lemproof2}), (\ref{eq:lemproof3}), отримуємо твердження
леми. \qed

Оскільки
\begin{equation*}
F_k(t) = 1 - \pint\limits _{(0, t]}(1 - d\Lambda _k(s)),
\end{equation*}
\begin{equation*}
\hat F_{k, n}(t) = 1 - \pint\limits _{(0, t]}(1 - d\hat \Lambda
_{k, n} (s)),
\end{equation*}
то за лемою \ref{lem:1} отримуємо
\begin{equation*}
\|\hat F _{k, n} - F_k\|_\infty \leq 4 \|F_k \|_v \exp (\|\hat
\Lambda _{k, n}\|_\infty ) \|\hat \Lambda _{k, n}\|_v \|\hat
\Lambda _{k, n} - \Lambda _k\|_\infty
\end{equation*}
Зрозуміло, що
 $\|F_k\|_v\leq 1$, $\|\hat \Lambda _{k, n}\|_\infty\le
 \|\Lambda _k \|_\infty + \eta _2 \ell _n (\overline{a}^k_n)^2$
 (за лемою \ref{lem:3}) і
 $$\|\hat\Lambda _{k, n} - \Lambda _k\|_\infty \leq \eta _2 \ell _n (\overline{ a}^k)^2.$$
Оцінимо $\|\hat \Lambda _{k, n}\|_v$ --- повну варіацію
$\hat \Lambda _{k,n}(t) = \int _{(0, t]}\frac {d\hat N_{k, n}(t)}{\hat Y_{k, n}(t)}$.
 Це стала функція на інтервалах між стрибками
 зі стрибками висоти
 $$\frac 1n \frac {a_j^k}{\hat Y_{k, n}(\xi ^* _j)}
 \leq \frac 1n \frac {\overline{a}^k}{\sigma _k },$$
  отже $\|\hat \Lambda _{k, n}\|_v \leq \frac {\overline{ a}^k_n}{\sigma _k }$. Тому
\begin{equation*}
\|\hat F_{k, n} - F_k\|\infty \leq 4
 \exp (\|\Lambda _k\|_\infty + \eta _2 \ell _n (\overline{ a}^k_n)^2)
 \frac {\overline{\mathbf a}^k}{\sigma _k }\eta _2\ell _n(\overline{
 a}^k_n)^2.
\end{equation*}

 Враховуючи, що, за умовою теореми, $\ell_n
 (\overline{a}_n^k)^2\to\infty$, отримуємо твердження теореми.
\qed

\section{Результати імітаційного моделювання}
 \label{sec:modeluvannia} Для перевірки поведінки запропонованих
 оцінок на вибірках помірного обсягу було проведене невелике дослідження
 методом імітаційного моделювання. Розглядалась модель суміші двох
 компонентів. Перший компонент мав хі-квадрат розподіл з трьома
 ступенями вільності, другий --- півнормальний розподіл. Для обох
 компонентів розподіл цензора був однаковим --- експоненційним з
 параметром $\lambda=0.1$. Концентрації компонентів у суміші дорівнювали
 $w^1_j = \frac jn$ та
  $w^2_j = 1 - \frac jn$ ($j=1,\ldots ,n$) відповідно. Для кожного
  розглянутого обсягу вибірки $n$ було згенеровано 1000 вибірок з
  суміші зі змінними концентраціями, за якими проводилось
  оцінювання розподілів першого та другого компонента з
  використанням оцінки $\hat F_{k,n}(t)$, визначеної \ref{eq:KMM}.

  Для характеризації якості оцінювання використовуються два
  підходи. При першому підході оцінка обчислюється у фіксованій
  точці $t=1.85$ і підраховується медіана (Median) її відхилення від
  справжнього значення функції розподілу та інтерквартильний
  розмах (IQR). (Ці робастні міри середнього положення та розкиду
  використані для того, щоб усунути вплив викидів, що виникають
  при малих обсягах вибірок).
  При другому підході для кожної модельованої вибірки
  обчислюється супремум різниці між оцінкою та справжньою функцією
  розподілу і знаходиться медіана цих супремумів по всіх вибірках (Med-Sup).


   Результати моделювання наведені у таблиці.

\begin{center}
Результати моделювання
\end{center}
\begin{center}
    \begin{tabular}{ | c | c | c | c || c | c | c |}
    \hline
     & \multicolumn{3}{ |c|| }{Перший компонент}& \multicolumn{3}{ |c| }{Другий
     компонент}\\
     \hline
    n & Median & IQR & Med-Sup & Median & IQR & Med-Sup \\
    \hline
    100  & 0,00891 & 0,13706  & 0,18477 & 0,01178 & 0,13682 &  0,17725   \\
    250  & 0,00573 & 0,08855  & 0,11843 & 0,00601 & 0,08707 &  0,11373   \\
    500  & 0,00444 & 0,06563  & 0,08587 & 0,00018 & 0,05965 &  0,07835    \\
    1000 & 0,00339 & 0,04426  & 0,06088 & 0,00072 & 0,04428 &  0,05666    \\
    2000 & 0,00063 & 0,03114  & 0,04429 & -0,0003 & 0,03106 &  0,04010    \\
    \hline
    \end{tabular}
\end{center}
 Ці результати свідчать про досить швидку збіжність оцінок до
 справжніх значень оцінюваних функцій.

 \section{Висновки}

 Ми побудували модифікацію оцінки Каплана-Мейера для оцінювання
 функцій розподілу компонентів суміші зі змінними концентраціями
 за цензурованими даними і довели її консистентність за досить
 широких умов. Результати моделювання свідчать про достатньо
 хорошу поведінку оцінки при помірних обсягах вибірки. Можна
 сподіватись, що техніка, запропонована у \cite{GJ} для доведення
 асимптотичної нормальності звичайних оцінок Каплана-Мейера за
 однорідними вибірками, дозволить отримати аналогічний результат і
 для нашої модифікації. Це має бути предметом подальших
 досліджень.

\begin{thebibliography}{1}

\bibitem{Korosteleva}
  Korosteleva O.  \textit{Clinical Statistics: Introducing
Clinical Trials, Survival Analysis, and Longitudinal Data
Analysis},  Jones and Bartlett Publishers: Sudbury, MA, 2008, 120
p.
\bibitem{HLMN}
Huber C.,  Limnios N.,  Mesbah M.,  Nikulin M.
\textit{Mathematical methods in survival analysis, reliability and
quality of life} ISTE \& Wiley, London \& Hoboken, NJ, 2008, 370p.

\bibitem{Shao}
Shao J. \textit{Mathematical statistics.} - Springer-Verlag: New
York,
 1998. - 530 p.

\bibitem{MS}
 Maiboroda R., Sugakova O.  Statistics of mixtures with
varying concentrations with application to DNA microarray data
analysis, \textit{Journal of Nonparametric Statistics}, 2012,24:1,
201-215

\bibitem{MSua}
 Майборода Р.Є., Сугакова О.В. \textit{Оцінювання та класифікація за спостереженнями із
 суміші.}
 - К.: ВПЦ "Київський ун-т", 2008. - 213 с.

\bibitem{Ryzhov}
Рижов А.Ю. Оцінки розподілів компонент суміші по цензурованим
 даним.- \textit{Теорія ймовірностей та математична статистика.}--- 2003,
 Вип. 69.--- с.154-161.

  \bibitem{Sherbina2011}
 Щербіна А.М. Оцніювання середнього у моделі сумішей зі змінними
 концентраціями// Теорія ймовірностей та математична статистика.--
 2011.-- Т. 84.-- С. 142-154.

  \bibitem{AutinPouet}
 Autin F., Pouet C. Minimax rates over Besov spaces in ill-conditioned
  mixture-models with varying mixing-weights//
  Journal of Statistical Planning and Inference
 V 146, 2014, p. 20–30.


\bibitem{GJ}
Gill R. D., Johansen S., A Survey of Product-Integration with a
View Toward application in Survival Analysis, \textit{Ann.
Statist.} 1990, 18 N 4, 1501-1555.

\end{thebibliography}

\end{document}
